{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06730e19-b084-4408-b1b3-3e897b8b9724",
   "metadata": {},
   "source": [
    "### 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6d881e-b98d-4e59-951f-592a7a86eb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProjectFolderName = 'mouse-adm1-2022-08-22'\n",
    "VideoType = 'avi' \n",
    "videofile_path = ['/mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi'] #Enter the list of videos or folder to analyze.\n",
    "videofile_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591a08e8-6713-46ff-b846-aa8767ede832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.2...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/__init__.py:81: UserWarning: \n",
      "        As PyTorch is not installed, unsupervised identity learning will not be available.\n",
      "        Please run `pip install torch`, or ignore this warning.\n",
      "        \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DLClight\"]=\"True\"\n",
    "import deeplabcut\n",
    "#设置config.yaml的位置\n",
    "path_config_file = '/mnt/mouse-adm1-2022-08-22/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d5752b-a307-4f3f-b221-213aeb5a79e7",
   "metadata": {},
   "source": [
    "### 载入标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11feaf62-ba79-4594-b784-c6d820f21e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not an official demo dataset.\n",
      "Loaded, now creating training data...\n",
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.load_demo_data(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4333c09c-7666-45d8-b5d8-f1fab017f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by adm1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:05<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Perhaps plot the labels to see how the frames were annotated:\n",
    "deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432be19f-bd79-431e-b9ce-5d76c2b618db",
   "metadata": {},
   "source": [
    "### 训练特征检测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fba8ef5-423e-4659-b7bd-fd731248324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['Nose',\n",
      "                      'L_Ear',\n",
      "                      'R_Ear',\n",
      "                      'Throat',\n",
      "                      'Back',\n",
      "                      'L_Sholder',\n",
      "                      'R_Sholder',\n",
      "                      'TailRoot',\n",
      "                      'TailMiddle',\n",
      "                      'TailEnd'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_mouseAug22/mouse_adm195shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/root/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_mouseAug22/Documentation_data-mouse_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/mnt/mouse-adm1-2022-08-22',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/mnt/mouse-adm1-2022-08-22/dlc-models/iteration-0/mouseAug22-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n",
      "2022-09-02 07:10:55.481932: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-02 07:10:56.575670: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-09-02 07:10:56.576290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:0b:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 07:10:57.508972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:0b:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display_iters overwritten as 10\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/mnt/mouse-adm1-2022-08-22/dlc-models/iteration-0/mouseAug22-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]], 'all_joints_names': ['Nose', 'L_Ear', 'R_Ear', 'Throat', 'Back', 'L_Sholder', 'R_Sholder', 'TailRoot', 'TailMiddle', 'TailEnd'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_mouseAug22/mouse_adm195shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/root/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_mouseAug22/Documentation_data-mouse_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 10, 'pos_dist_thresh': 17, 'project_path': '/mnt/mouse-adm1-2022-08-22', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 07:11:04.564631: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "iteration: 10 loss: 0.4054 lr: 0.005\n",
      "iteration: 20 loss: 0.0531 lr: 0.005\n",
      "iteration: 30 loss: 0.0422 lr: 0.005\n",
      "iteration: 40 loss: 0.0369 lr: 0.005\n",
      "iteration: 50 loss: 0.0338 lr: 0.005\n",
      "iteration: 60 loss: 0.0311 lr: 0.005\n",
      "iteration: 70 loss: 0.0327 lr: 0.005\n",
      "iteration: 80 loss: 0.0284 lr: 0.005\n",
      "iteration: 90 loss: 0.0295 lr: 0.005\n",
      "iteration: 100 loss: 0.0299 lr: 0.005\n",
      "iteration: 110 loss: 0.0254 lr: 0.005\n",
      "iteration: 120 loss: 0.0273 lr: 0.005\n",
      "iteration: 130 loss: 0.0256 lr: 0.005\n",
      "iteration: 140 loss: 0.0320 lr: 0.005\n",
      "iteration: 150 loss: 0.0268 lr: 0.005\n",
      "iteration: 160 loss: 0.0287 lr: 0.005\n",
      "iteration: 170 loss: 0.0284 lr: 0.005\n",
      "iteration: 180 loss: 0.0277 lr: 0.005\n",
      "iteration: 190 loss: 0.0269 lr: 0.005\n",
      "iteration: 200 loss: 0.0275 lr: 0.005\n",
      "iteration: 210 loss: 0.0222 lr: 0.005\n",
      "iteration: 220 loss: 0.0259 lr: 0.005\n",
      "iteration: 230 loss: 0.0263 lr: 0.005\n",
      "iteration: 240 loss: 0.0220 lr: 0.005\n",
      "iteration: 250 loss: 0.0278 lr: 0.005\n",
      "iteration: 260 loss: 0.0240 lr: 0.005\n",
      "iteration: 270 loss: 0.0261 lr: 0.005\n",
      "iteration: 280 loss: 0.0274 lr: 0.005\n",
      "iteration: 290 loss: 0.0246 lr: 0.005\n",
      "iteration: 300 loss: 0.0230 lr: 0.005\n",
      "iteration: 310 loss: 0.0258 lr: 0.005\n",
      "iteration: 320 loss: 0.0235 lr: 0.005\n",
      "iteration: 330 loss: 0.0254 lr: 0.005\n",
      "iteration: 340 loss: 0.0240 lr: 0.005\n",
      "iteration: 350 loss: 0.0232 lr: 0.005\n",
      "iteration: 360 loss: 0.0250 lr: 0.005\n",
      "iteration: 370 loss: 0.0204 lr: 0.005\n",
      "iteration: 380 loss: 0.0228 lr: 0.005\n",
      "iteration: 390 loss: 0.0194 lr: 0.005\n",
      "iteration: 400 loss: 0.0228 lr: 0.005\n",
      "iteration: 410 loss: 0.0235 lr: 0.005\n",
      "iteration: 420 loss: 0.0227 lr: 0.005\n",
      "iteration: 430 loss: 0.0216 lr: 0.005\n",
      "iteration: 440 loss: 0.0203 lr: 0.005\n",
      "iteration: 450 loss: 0.0236 lr: 0.005\n",
      "iteration: 460 loss: 0.0245 lr: 0.005\n",
      "iteration: 470 loss: 0.0261 lr: 0.005\n",
      "iteration: 480 loss: 0.0213 lr: 0.005\n",
      "iteration: 490 loss: 0.0214 lr: 0.005\n",
      "iteration: 500 loss: 0.0214 lr: 0.005\n",
      "iteration: 510 loss: 0.0197 lr: 0.005\n",
      "iteration: 520 loss: 0.0217 lr: 0.005\n",
      "iteration: 530 loss: 0.0216 lr: 0.005\n",
      "iteration: 540 loss: 0.0213 lr: 0.005\n",
      "iteration: 550 loss: 0.0247 lr: 0.005\n",
      "iteration: 560 loss: 0.0240 lr: 0.005\n",
      "iteration: 570 loss: 0.0209 lr: 0.005\n",
      "iteration: 580 loss: 0.0236 lr: 0.005\n",
      "iteration: 590 loss: 0.0221 lr: 0.005\n",
      "iteration: 600 loss: 0.0232 lr: 0.005\n",
      "iteration: 610 loss: 0.0212 lr: 0.005\n",
      "iteration: 620 loss: 0.0197 lr: 0.005\n",
      "iteration: 630 loss: 0.0224 lr: 0.005\n",
      "iteration: 640 loss: 0.0198 lr: 0.005\n",
      "iteration: 650 loss: 0.0177 lr: 0.005\n",
      "iteration: 660 loss: 0.0243 lr: 0.005\n",
      "iteration: 670 loss: 0.0191 lr: 0.005\n",
      "iteration: 680 loss: 0.0238 lr: 0.005\n",
      "iteration: 690 loss: 0.0206 lr: 0.005\n",
      "iteration: 700 loss: 0.0222 lr: 0.005\n",
      "iteration: 710 loss: 0.0235 lr: 0.005\n",
      "iteration: 720 loss: 0.0153 lr: 0.005\n",
      "iteration: 730 loss: 0.0199 lr: 0.005\n",
      "iteration: 740 loss: 0.0182 lr: 0.005\n",
      "iteration: 750 loss: 0.0185 lr: 0.005\n",
      "iteration: 760 loss: 0.0191 lr: 0.005\n",
      "iteration: 770 loss: 0.0197 lr: 0.005\n",
      "iteration: 780 loss: 0.0185 lr: 0.005\n",
      "iteration: 790 loss: 0.0206 lr: 0.005\n",
      "iteration: 800 loss: 0.0186 lr: 0.005\n",
      "iteration: 810 loss: 0.0206 lr: 0.005\n",
      "iteration: 820 loss: 0.0201 lr: 0.005\n",
      "iteration: 830 loss: 0.0213 lr: 0.005\n",
      "iteration: 840 loss: 0.0207 lr: 0.005\n",
      "iteration: 850 loss: 0.0149 lr: 0.005\n",
      "iteration: 860 loss: 0.0197 lr: 0.005\n",
      "iteration: 870 loss: 0.0188 lr: 0.005\n",
      "iteration: 880 loss: 0.0172 lr: 0.005\n",
      "iteration: 890 loss: 0.0169 lr: 0.005\n",
      "iteration: 900 loss: 0.0190 lr: 0.005\n",
      "iteration: 910 loss: 0.0203 lr: 0.005\n",
      "iteration: 920 loss: 0.0162 lr: 0.005\n",
      "iteration: 930 loss: 0.0160 lr: 0.005\n",
      "iteration: 940 loss: 0.0193 lr: 0.005\n",
      "iteration: 950 loss: 0.0188 lr: 0.005\n",
      "iteration: 960 loss: 0.0171 lr: 0.005\n",
      "iteration: 970 loss: 0.0187 lr: 0.005\n",
      "iteration: 980 loss: 0.0202 lr: 0.005\n",
      "iteration: 990 loss: 0.0158 lr: 0.005\n",
      "iteration: 1000 loss: 0.0150 lr: 0.005\n",
      "iteration: 1010 loss: 0.0195 lr: 0.005\n",
      "iteration: 1020 loss: 0.0191 lr: 0.005\n",
      "iteration: 1030 loss: 0.0175 lr: 0.005\n",
      "iteration: 1040 loss: 0.0156 lr: 0.005\n",
      "iteration: 1050 loss: 0.0164 lr: 0.005\n",
      "iteration: 1060 loss: 0.0167 lr: 0.005\n",
      "iteration: 1070 loss: 0.0215 lr: 0.005\n",
      "iteration: 1080 loss: 0.0201 lr: 0.005\n",
      "iteration: 1090 loss: 0.0133 lr: 0.005\n",
      "iteration: 1100 loss: 0.0173 lr: 0.005\n",
      "iteration: 1110 loss: 0.0150 lr: 0.005\n",
      "iteration: 1120 loss: 0.0198 lr: 0.005\n",
      "iteration: 1130 loss: 0.0199 lr: 0.005\n",
      "iteration: 1140 loss: 0.0181 lr: 0.005\n",
      "iteration: 1150 loss: 0.0176 lr: 0.005\n",
      "iteration: 1160 loss: 0.0169 lr: 0.005\n",
      "iteration: 1170 loss: 0.0139 lr: 0.005\n",
      "iteration: 1180 loss: 0.0176 lr: 0.005\n",
      "iteration: 1190 loss: 0.0192 lr: 0.005\n",
      "iteration: 1200 loss: 0.0174 lr: 0.005\n",
      "iteration: 1210 loss: 0.0171 lr: 0.005\n",
      "iteration: 1220 loss: 0.0172 lr: 0.005\n",
      "iteration: 1230 loss: 0.0156 lr: 0.005\n",
      "iteration: 1240 loss: 0.0161 lr: 0.005\n",
      "iteration: 1250 loss: 0.0180 lr: 0.005\n",
      "iteration: 1260 loss: 0.0196 lr: 0.005\n",
      "iteration: 1270 loss: 0.0166 lr: 0.005\n",
      "iteration: 1280 loss: 0.0204 lr: 0.005\n",
      "iteration: 1290 loss: 0.0182 lr: 0.005\n",
      "iteration: 1300 loss: 0.0159 lr: 0.005\n",
      "iteration: 1310 loss: 0.0156 lr: 0.005\n",
      "iteration: 1320 loss: 0.0180 lr: 0.005\n",
      "iteration: 1330 loss: 0.0168 lr: 0.005\n",
      "iteration: 1340 loss: 0.0163 lr: 0.005\n",
      "iteration: 1350 loss: 0.0154 lr: 0.005\n",
      "iteration: 1360 loss: 0.0141 lr: 0.005\n",
      "iteration: 1370 loss: 0.0181 lr: 0.005\n",
      "iteration: 1380 loss: 0.0168 lr: 0.005\n",
      "iteration: 1390 loss: 0.0195 lr: 0.005\n",
      "iteration: 1400 loss: 0.0135 lr: 0.005\n",
      "iteration: 1410 loss: 0.0163 lr: 0.005\n",
      "iteration: 1420 loss: 0.0159 lr: 0.005\n",
      "iteration: 1430 loss: 0.0173 lr: 0.005\n",
      "iteration: 1440 loss: 0.0146 lr: 0.005\n",
      "iteration: 1450 loss: 0.0168 lr: 0.005\n",
      "iteration: 1460 loss: 0.0155 lr: 0.005\n",
      "iteration: 1470 loss: 0.0159 lr: 0.005\n",
      "iteration: 1480 loss: 0.0165 lr: 0.005\n",
      "iteration: 1490 loss: 0.0175 lr: 0.005\n",
      "iteration: 1500 loss: 0.0168 lr: 0.005\n",
      "iteration: 1510 loss: 0.0153 lr: 0.005\n",
      "iteration: 1520 loss: 0.0163 lr: 0.005\n",
      "iteration: 1530 loss: 0.0167 lr: 0.005\n",
      "iteration: 1540 loss: 0.0163 lr: 0.005\n",
      "iteration: 1550 loss: 0.0166 lr: 0.005\n",
      "iteration: 1560 loss: 0.0168 lr: 0.005\n",
      "iteration: 1570 loss: 0.0156 lr: 0.005\n",
      "iteration: 1580 loss: 0.0175 lr: 0.005\n",
      "iteration: 1590 loss: 0.0162 lr: 0.005\n",
      "iteration: 1600 loss: 0.0167 lr: 0.005\n",
      "iteration: 1610 loss: 0.0184 lr: 0.005\n",
      "iteration: 1620 loss: 0.0143 lr: 0.005\n",
      "iteration: 1630 loss: 0.0150 lr: 0.005\n",
      "iteration: 1640 loss: 0.0163 lr: 0.005\n",
      "iteration: 1650 loss: 0.0152 lr: 0.005\n",
      "iteration: 1660 loss: 0.0139 lr: 0.005\n",
      "iteration: 1670 loss: 0.0157 lr: 0.005\n",
      "iteration: 1680 loss: 0.0167 lr: 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_122/1631000730.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#notice the variables \"saveiters\" and \"dsiplayiters\" that can be set in the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#you just need to run this until you get at least 1 snapshot, which is set by: \"save_iters\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#(so in this case you could stop after 500!) How do I stop? Click the STOP button!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selecting single-animal trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             train(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mlr_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         [_, loss_val, summary] = sess.run(\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1371\u001b[0m                            run_metadata)\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1361\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1452\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1453\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, shuffle=1, saveiters=1000, displayiters=10)\n",
    "#notice the variables \"saveiters\" and \"dsiplayiters\" that can be set in the function\n",
    "\n",
    "#you just need to run this until you get at least 1 snapshot, which is set by: \"save_iters\" \n",
    "#(so in this case you could stop after 500!) How do I stop? Click the STOP button!\n",
    "# To train until ~2,000 iterations on a CPU should be ~30 min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a28f57-a597-4595-b04c-97a49a5fa862",
   "metadata": {},
   "source": [
    "### 评价训练好的特征网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec05d70-fac4-447e-ab6f-4ccb9a5263b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['Nose',\n",
      "                      'L_Ear',\n",
      "                      'R_Ear',\n",
      "                      'Throat',\n",
      "                      'Back',\n",
      "                      'L_Sholder',\n",
      "                      'R_Sholder',\n",
      "                      'TailRoot',\n",
      "                      'TailMiddle',\n",
      "                      'TailEnd'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_mouseAug22/mouse_adm195shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/root/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/mnt/mouse-adm1-2022-08-22/dlc-models/iteration-0/mouseAug22-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_mouseAug22shuffle1_3000  with # of training iterations: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 15:01:44.967312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:10:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:04,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-3000\n",
      "Results for 3000  training iterations: 95 1 train error: 7.84 pixels. Test error: 11.2  pixels.\n",
      "With pcutoff of 0.6  train error: 6.29 pixels. Test error: 4.47 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:07<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJJElEQVR4nO3WwQ3AIBDAsNL9dz52IA+EZE+QZ9bMfAAAcOq/HQAAwNsMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAACJoQQAIDGUAAAkhhIAgMRQAgCQGEoAABJDCQBAYigBAEgMJQAAiaEEACAxlAAAJIYSAIDEUAIAkBhKAAASQwkAQGIoAQBIDCUAAImhBAAgMZQAACSGEgCAxFACAJAYSgAAEkMJAEBiKAEASAwlAADJBpmGBuPyuImhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fca940-703b-4f1a-8b30-39c1be674a78",
   "metadata": {},
   "source": [
    "### 分析视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af762ae3-e5fa-441a-a814-6030d44e510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['Nose',\n",
      "                      'L_Ear',\n",
      "                      'R_Ear',\n",
      "                      'Throat',\n",
      "                      'Back',\n",
      "                      'L_Sholder',\n",
      "                      'R_Sholder',\n",
      "                      'TailRoot',\n",
      "                      'TailMiddle',\n",
      "                      'TailEnd'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_mouseAug22/mouse_adm195shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/root/miniconda3/envs/myconda/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/mnt/mouse-adm1-2022-08-22/dlc-models/iteration-0/mouseAug22-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-3000 for model /mnt/mouse-adm1-2022-08-22/dlc-models/iteration-0/mouseAug22-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 15:03:03.771534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:10:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi\n",
      "Loading  /mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi\n",
      "Duration of video [s]:  33.33 , recorded with  30.0 fps!\n",
      "Overall # of frames:  1000  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:03<00:00, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /mnt/mouse-adm1-2022-08-22/videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_mouseAug22shuffle1_3000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype=VideoType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb49bb-9ceb-4cb6-a543-2cc37bdfb635",
   "metadata": {},
   "source": [
    "### 创建带有标注的视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79f2235-15cd-4876-b873-fb05bf227209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: /mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi\n",
      "Loading /mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi and data.\n",
      "Duration of video [s]: 33.33, recorded with 30.0 fps!\n",
      "Overall # of frames: 1000 with cropped frame dimensions: 640 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 119.47it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file, videofile_path, draw_skeleton=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f3c980-8957-4cec-8dc4-952e6e592dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  /mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "#在视频上绘制关键点\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path, videotype=VideoType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208f635f-4315-41f5-befa-86718f4c2388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function deeplabcut.refine_training_dataset.outlier_frames.extract_outlier_frames(config, videos, videotype='', shuffle=1, trainingsetindex=0, outlieralgorithm='jump', comparisonbodyparts='all', epsilon=20, p_bound=0.01, ARdegree=3, MAdegree=1, alpha=0.01, extractionalgorithm='kmeans', automatic=False, cluster_resizewidth=30, cluster_color=False, opencv=True, savelabeled=False, destfolder=None, modelprefix='', track_method='')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.extract_outlier_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a0f43ce-cb09-434e-9cde-614716215629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  uncertain  found  32  putative outlier frames.\n",
      "Do you want to proceed with extracting  40  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video behavCam3  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  33.333333333333336 , recorded @  30.0 fps!\n",
      "Overall # of frames:  1000 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 33.33  seconds.\n",
      "Let's select frames indices: [31, 32, 33, 34, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 62, 65, 75, 76, 78, 79, 93, 94, 95, 96, 689, 690, 776]\n",
      "Attempting to create a symbolic link of the video ...\n",
      "Symlink creation impossible (exFat architecture?): cutting/pasting the video instead.\n",
      "videos/behavCam3.avi moved to /mnt/mouse-adm1-2022-08-22/videos/behavCam3.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\behavCam3.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: mklink: not found\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,videofile_path,outlieralgorithm='uncertain',p_bound=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
